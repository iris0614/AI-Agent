{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as Chinook.db\n",
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n",
      "The tables provided do not contain a direct link between sales agents and invoices. The \"Employee\" table lists employees, including sales agents, but does not directly associate them with sales data in the \"Invoice\" table. Therefore, it's not possible to determine which sales agent made the most in sales in 2009 with the given database schema.\n",
      "{'first_tool_call': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={}, id='bea66952-6c3c-48c8-acc1-3a999be638a3', tool_calls=[{'name': 'sql_db_list_tables', 'args': {}, 'id': 'tool_abcd123', 'type': 'tool_call'}])]}}\n",
      "{'list_tables_tool': {'messages': [ToolMessage(content='Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', name='sql_db_list_tables', id='89581690-cf29-4978-9637-b36a8a340f6d', tool_call_id='tool_abcd123')]}}\n",
      "{'model_get_schema': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xVctyvTHOfJQLIEJxbPLdSPo', 'function': {'arguments': '{\"table_names\":\"Invoice, Employee\"}', 'name': 'sql_db_schema'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 177, 'total_tokens': 195, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_2f406b9113', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-dfddfa00-57b6-469d-ae0a-3fffc1e9f8f8-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'Invoice, Employee'}, 'id': 'call_xVctyvTHOfJQLIEJxbPLdSPo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 18, 'total_tokens': 195})]}}\n",
      "{'get_schema_tool': {'messages': [ToolMessage(content='\\nCREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/', name='sql_db_schema', id='773c3339-2706-4510-9160-07fdf3794b31', tool_call_id='call_xVctyvTHOfJQLIEJxbPLdSPo')]}}\n",
      "{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cBdryJrV2hZagYZZKBFhU0xX', 'function': {'arguments': '{\"final_answer\":\"The database does not contain a direct link between sales agents and invoices. The \\\\\"Employee\\\\\" table lists employees, including sales agents, but there is no direct association with sales data in the \\\\\"Invoice\\\\\" table. Therefore, it\\'s not possible to determine which sales agent made the most in sales in 2009 based on the available data.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 968, 'total_tokens': 1051, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_2f406b9113', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c7c62cc5-a1a4-47f9-80e0-6ccac648d553-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The database does not contain a direct link between sales agents and invoices. The \"Employee\" table lists employees, including sales agents, but there is no direct association with sales data in the \"Invoice\" table. Therefore, it\\'s not possible to determine which sales agent made the most in sales in 2009 based on the available data.'}, 'id': 'call_cBdryJrV2hZagYZZKBFhU0xX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 968, 'output_tokens': 83, 'total_tokens': 1051})]}}\n",
      "View the evaluation results for experiment: 'sql-agent-multi-step-response-v-reference-0967f5d6' at:\n",
      "https://smith.langchain.com/o/dfc90241-3b68-558f-9df8-8c3f5880f557/datasets/ba8bac7d-cbb8-4d25-a78d-16ef39d7c103/compare?selectedSessions=ad645231-e447-4478-b40b-12b973f939ae\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973f322fd8614bd995c8796262176e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, Literal\n",
    "from langchain_core.messages import AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from typing import Any\n",
    "\n",
    "# Load environment variables (if any)\n",
    "load_dotenv()\n",
    "\n",
    "# Download and save the Chinook database locally\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"Chinook.db\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded and saved as Chinook.db\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "\n",
    "# Initialize the SQLDatabase instance\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "\n",
    "# Define a utility function to print SQL results and check output\n",
    "def print_and_return_result(query):\n",
    "    result = db.run(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Result: {result}\")\n",
    "    return result\n",
    "\n",
    "# Validate SQL query results for common cases and errors\n",
    "def validate_sql_result(query, expected_output):\n",
    "    result = db.run(query)\n",
    "    if result == expected_output:\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Validation failed for query: {query}\")\n",
    "        print(f\"Expected: {expected_output}, Got: {result}\")\n",
    "        return False\n",
    "\n",
    "# Error handler for SQL tool\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Create a tool node with a fallback mechanism\n",
    "def create_tool_node_with_fallback(tools: list) -> RunnableWithFallbacks[Any, dict]:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "# Create SQLDatabaseToolkit and bind the tools\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(model=\"gpt-4o\"))\n",
    "tools = toolkit.get_tools()\n",
    "list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "\n",
    "# Query execution tool\n",
    "@tool\n",
    "def db_query_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute a SQL query against the database and get back the result.\n",
    "    If the query is not correct, an error message will be returned.\n",
    "    If an error is returned, rewrite the query, check the query, and try again.\n",
    "    \"\"\"\n",
    "    result = db.run_no_throw(query)\n",
    "    if not result:\n",
    "        return \"Error: Query failed. Please rewrite your query and try again.\"\n",
    "    return result\n",
    "\n",
    "# Sample query to validate functionality\n",
    "print(db_query_tool.invoke(\"SELECT * FROM Artist LIMIT 10;\"))\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Query check system for SQL validation\n",
    "query_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "Double-check the SQLite query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are mistakes, rewrite the query. If no mistakes, reproduce the original query.\"\"\"\n",
    "\n",
    "# Generate prompt and bind to the query tool\n",
    "query_check_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "query_check = query_check_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n",
    "    [db_query_tool], tool_choice=\"required\"\n",
    ")\n",
    "\n",
    "# Check and execute query\n",
    "query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n",
    "\n",
    "# Define agent state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Create new StateGraph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Initial tool call for the agent\n",
    "def first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[{\"name\": \"sql_db_list_tables\", \"args\": {}, \"id\": \"tool_abcd123\"}],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Function to check query correctness\n",
    "def model_check_query(state: State) -> dict[str, list[AIMessage]]:\n",
    "    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
    "\n",
    "# Add nodes to workflow\n",
    "workflow.add_node(\"first_tool_call\", first_tool_call)\n",
    "workflow.add_node(\"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool]))\n",
    "workflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n",
    "\n",
    "# Model for schema selection\n",
    "model_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools([get_schema_tool])\n",
    "workflow.add_node(\"model_get_schema\", lambda state: {\"messages\": [model_get_schema.invoke(state[\"messages\"])]})\n",
    "\n",
    "# Final answer submission\n",
    "class SubmitFinalAnswer(BaseModel):\n",
    "    final_answer: str = Field(..., description=\"The final answer to the user\")\n",
    "\n",
    "# Generate a query based on question and schema\n",
    "query_gen_system = \"\"\"You are a SQL expert with strong attention to detail.\n",
    "Generate a syntactically correct SQLite query, execute it, and return the results.\n",
    "\n",
    "If an error occurs during query execution, rewrite and retry the query.\n",
    "Never make up data, and avoid DML statements.\"\"\"\n",
    "\n",
    "query_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "query_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n",
    "    [SubmitFinalAnswer]\n",
    ")\n",
    "\n",
    "# Query generation node\n",
    "def query_gen_node(state: State):\n",
    "    message = query_gen.invoke(state)\n",
    "    tool_messages = []\n",
    "    if message.tool_calls:\n",
    "        for tc in message.tool_calls:\n",
    "            if tc[\"name\"] != \"SubmitFinalAnswer\":\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=f\"Error: Wrong tool called: {tc['name']}. Please fix the query and remember to call only SubmitFinalAnswer.\",\n",
    "                        tool_call_id=tc[\"id\"],\n",
    "                    )\n",
    "                )\n",
    "    return {\"messages\": [message] + tool_messages}\n",
    "\n",
    "# Add nodes for query generation, correction, and execution\n",
    "workflow.add_node(\"query_gen\", query_gen_node)\n",
    "workflow.add_node(\"correct_query\", model_check_query)\n",
    "workflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n",
    "\n",
    "# Conditional flow to determine if the query needs correction or is complete\n",
    "def should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if getattr(last_message, \"tool_calls\", None):\n",
    "        return END\n",
    "    if last_message.content.startswith(\"Error:\"):\n",
    "        return \"query_gen\"\n",
    "    return \"correct_query\"\n",
    "\n",
    "# Define edges between nodes\n",
    "workflow.add_edge(START, \"first_tool_call\")\n",
    "workflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\n",
    "workflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\n",
    "workflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\n",
    "workflow.add_edge(\"get_schema_tool\", \"query_gen\")\n",
    "workflow.add_conditional_edges(\"query_gen\", should_continue)\n",
    "workflow.add_edge(\"correct_query\", \"execute_query\")\n",
    "workflow.add_edge(\"execute_query\", \"query_gen\")\n",
    "\n",
    "# Compile the workflow into a runnable application\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the app with sample user input\n",
    "messages = app.invoke(\n",
    "    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n",
    ")\n",
    "json_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\n",
    "print(json_str)\n",
    "\n",
    "# Stream the events as they occur\n",
    "for event in app.stream(\n",
    "    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n",
    "):\n",
    "    print(event)\n",
    "\n",
    "import json\n",
    "\n",
    "# Predict SQL agent answer for evaluation\n",
    "def predict_sql_agent_answer(example: dict):\n",
    "    msg = {\"messages\": (\"user\", example[\"input\"])}\n",
    "    messages = app.invoke(msg)\n",
    "    json_str = messages[\"messages\"][-1].tool_calls[0][\"args\"]\n",
    "    response = json_str[\"final_answer\"]\n",
    "    return {\"response\": response}\n",
    "\n",
    "# RAG-based evaluation for SQL agent\n",
    "from langchain import hub\n",
    "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "# Answer evaluator using RAG\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    input_question = example.inputs[\"input\"]\n",
    "    reference = example.outputs[\"output\"]\n",
    "    prediction = run.outputs[\"response\"]\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "    score = answer_grader.invoke({\n",
    "        \"question\": input_question,\n",
    "        \"correct_answer\": reference,\n",
    "        \"student_answer\": prediction,\n",
    "    })\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score[\"Score\"]}\n",
    "\n",
    "# Experiment evaluation with LangSmith\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "dataset_name = \"SQL Agent Response\"\n",
    "try:\n",
    "    experiment_results = evaluate(\n",
    "        predict_sql_agent_answer,\n",
    "        data=dataset_name,\n",
    "        evaluators=[answer_evaluator],\n",
    "        num_repetitions=3,\n",
    "        experiment_prefix=\"sql-agent-multi-step-response-v-reference\",\n",
    "        metadata={\"version\": \"Chinook, gpt-4o multi-step-agent\"},\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "575",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
